{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from collections import Counter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, import the package needed in this project. Then import the data from a csv file which is copied from the question. As is shown in the file, the data is composed of 4 attributes and 1 label('A','B' or 'C'). Then shuffle the data and randomly select training data and testing data from the dataset. The size of the training/testing data can be modified using the variable testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv',header=None,dtype=str)[0].str.split(',',expand=True)\n",
    "df_array = df[:].values\n",
    "df_x = df_array[:,:4].astype(np.float64)# Attributes\n",
    "df_y = df_array[:,-1]#labels\n",
    "index_shuffle = np.arange(len(df_y)) \n",
    "np.random.shuffle(index_shuffle)#shuffle the data\n",
    "testsize=30\n",
    "xtrain = df_x[index_shuffle[:-testsize]]#Randomly select traing set and testing set\n",
    "ytrain = df_y[index_shuffle[:-testsize]]\n",
    "xtest = df_x[index_shuffle[-testsize:]]\n",
    "ytest = df_y[index_shuffle[-testsize:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the similarity(distance) between data instances. Here we consider the Euclidean distance which means:\n",
    "\n",
    "$$distance=\\sqrt{\\sum_{i=1}^{4}(x_{1i}-x_{2i})^2}$$\n",
    "\n",
    "The instances with higher distances are less similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(xtest,xtrain):\n",
    "    p=2\n",
    "    return ((xtest-xtrain)**p).sum(axis=1)**(1/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a function to find k nearest instance is defined below. For an instance from testing set(xtest), the difference between it and all the training instances(xtrain) are calculated. Then the index of instances with k smallest distances(k need input). Then function will return all the k instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knearest(xtrain,xtest,k):\n",
    "    p=2\n",
    "    distance=dis(xtest,xtrain)\n",
    "    index_Ksmall = distance.argsort()[:k]\n",
    "    Knearest=xtrain[:k]\n",
    "    return Knearest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the code below return the 30 nearest instance from the first instance in testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 2. , 3.5, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.3, 2.3, 4.4, 1.3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knearest(xtrain,xtest[0],30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the prediction data is defined. This KNN prediction function contains following steps:\n",
    "1. For the first instance in testing data(xtest), calculate the distances between all the training data(xtrain)\n",
    "2. Find the k nearest instances and find their classes from ytrain.\n",
    "3. Calculate the counts of the classes that show in the k nearest instances, and find the class with highest frequency as the prediction result.\n",
    "4. Repeat for rest of testing data and return the prediction result.\n",
    "\n",
    "With the prediction result we can calculate the accuracy, which is:\n",
    "$$accuracy = \\frac{count_{match}}{count_{testing}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(xtrain,ytrain,xtest,p):\n",
    "    k=12\n",
    "    y_predict=[]\n",
    "    for i in range(len(xtest)):\n",
    "        distance=dis(xtest[i],xtrain)\n",
    "        index_Ksmall = distance.argsort()[:k]\n",
    "        allClass = np.unique(ytrain[list(index_Ksmall)])\n",
    "        \n",
    "        Class_counts = Counter(allClass)\n",
    "        finalClass = Class_counts.most_common(1)[0][0]\n",
    "        y_predict.append(finalClass)\n",
    "    return np.array(y_predict)\n",
    "\n",
    "def accuracy(prediction_y,y_test):\n",
    "    return (prediction_y==y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the prediction result is shown below and the predict accuracy is 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C' 'C' 'A' 'A' 'A' 'B' 'B' 'C' 'B' 'A' 'C' 'C' 'C' 'B' 'B' 'A' 'A' 'A'\n",
      " 'B' 'B' 'B' 'A' 'A' 'A' 'B' 'B' 'B' 'C' 'B' 'B']\n"
     ]
    }
   ],
   "source": [
    "prediction_y=prediction(xtrain,ytrain,xtest,2)\n",
    "print(prediction_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(prediction_y,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Knearest function is modified that the output will be the mean result of the k nearest instances instead of all the instances. The result is calculated as:\n",
    "$$x_{mean,i}=\\frac{\\sum x_i}{k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knearest2(xtrain,xtest,k):\n",
    "    p=2\n",
    "    distance=((xtest-xtrain)**p).sum(axis=1)**(1/p)\n",
    "    index_Ksmall = distance.argsort()[:k]\n",
    "    Knearest=xtrain[:k].mean(axis=0)\n",
    "    return Knearest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.86333333, 3.09333333, 3.93333333, 1.35666667])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knearest2(xtrain,xtest[0],30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the normalization data. Each attribute is rescaled to the $[0,1]$ section, which means:\n",
    "$$x_{rescale}=\\frac{x-x_{min}}{x_{max}-x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(xtrain,xtest):\n",
    "    t1=copy.deepcopy(xtrain[:,:])\n",
    "    t2=copy.deepcopy(xtest[:,:])\n",
    "    for i in range(xtest.shape[1]):\n",
    "        t2[:,i]=(t2[:,i]-t1[:,i].min())/(t1[:,i].max()-t1[:,i].min())\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example is shown below. What should be noticed is that the accuracy is not necessarily higher after the normalization because the optimal weights for the attributes are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxtrain = normalize(xtrain,xtrain)\n",
    "nxtest = normalize(xtrain,xtest)\n",
    "y_pre2=prediction(nxtrain,ytrain,nxtest,2)\n",
    "accuracy(y_pre2,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new distance calculation function is defined as:\n",
    "$$distance=(\\sum_{i=1}^{4}|(x_{1i}-x_{2i})^p|)^\\frac{1}{p}$$\n",
    "Where p can be customized. When $p=2$, the distance will be Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp(xtest,xtrain,p):\n",
    "    return abs((xtest-xtrain)**p).sum(axis=1)**(1/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is shown below, for different p, the distances are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.7 2.2 4.4 2.8]\n",
      "[3.73764632 1.12249722 2.68700577 1.64316767]\n",
      "[3.19586053 0.90775197 2.34577481 1.4702278 ]\n",
      "[2.99014506 0.82256258 2.20546887 1.42430505]\n",
      "[2.88354549 0.77924347 2.12894633 1.40928563]\n",
      "[2.81803146 0.75418843 2.08053196 1.40376989]\n"
     ]
    }
   ],
   "source": [
    "for p in (1,2,3,4,5,6):\n",
    "    print(disp(xtest[0],xtrain[:4],p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
